### README.md Professionnel pour ton Portfolio de Scraping

```markdown
# üìö Web Scraper - Books to Scrape  
![Python](https://img.shields.io/badge/Python-3.10+-blue) 
![BeautifulSoup](https://img.shields.io/badge/BeautifulSoup-4.12-green)
![Requests](https://img.shields.io/badge/Requests-2.32-lightgrey)
![Last Commit](https://img.shields.io/github/last-commit/tonuser/web-scraping-portfolio)

> Scraper automatis√© pour extraire les donn√©es de livres du site "Books to Scrape" avec gestion de pagination et export JSON

## üöÄ Fonctionnalit√©s  
- Scraping multi-pages automatique (50+ pages)
- Extraction des titres, prix, notes et disponibilit√©
- Gestion robuste des erreurs et des timeout
- Export des donn√©es structur√©es en JSON
- Respect des bonnes pratiques de scraping (d√©lais, user-agents)

## üì∏ R√©sultat d'Extraction
```json
[
    {
        "title": "A Light in the Attic",
        "price": "¬£51.77",
        "rating": "Three stars",
        "availability": "In stock"
    },
    {
        "title": "Tipping the Velvet",
        "price": "¬£53.74",
        "rating": "One stars",
        "availability": "In stock"
    }
]
```

## üîß Installation  
1. Clonez le d√©p√¥t :
```bash
git clone https://github.com/tonuser/web-scraping-portfolio.git
cd web-scraping-portfolio
```

2. Cr√©ez un environnement virtuel :
```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.\.venv\Scripts\activate   # Windows
```

3. Installez les d√©pendances :
```bash
pip install -r requirements.txt
```

## üíª Utilisation  
Ex√©cutez le scraper principal :
```bash
python src/books_scraper.py
```

Les donn√©es seront sauvegard√©es dans :
- `books.json` (fichier complet)
- `data/sample_books.json` (√©chantillon)

## üåê Structure des Donn√©es
| Champ          | Description                  | Exemple              |
|----------------|------------------------------|----------------------|
| `title`        | Titre complet du livre       | "A Light in the Attic" |
| `price`        | Prix en GBP                  | "¬£51.77"            |
| `rating`       | Note en √©toiles (One √† Five) | "Three stars"       |
| `availability` | Statut de stock              | "In stock"          |

## üìä Workflow de Scraping
```mermaid
graph LR
A[Page 1] --> B{Analyse HTML}
B --> C[Extraction donn√©es]
C --> D[Page suivante?]
D -->|Oui| E[Page N+1]
D -->|Non| F[(Export JSON)]
```

## üß† Apprentissages Techniques
- Navigation pagin√©e avec BeautifulSoup
- S√©lecteurs CSS avanc√©s (`select_one`, `find_all`)
- Gestion des erreurs HTTP (404, timeout)
- Transformation des donn√©es structur√©es
- √âthique du web scraping (robots.txt, taux de requ√™tes)

## ü§ù Contributions  
Les contributions sont les bienvenues ! Pour proposer une am√©lioration :
1. Forkez le d√©p√¥t
2. Cr√©ez une branche (`git checkout -b feat/nouvelle-fonctionnalite`)
3. Committez vos changements (`git commit -m 'feat: ajout ...'`)
4. Pushez vers la branche (`git push origin feat/nouvelle-fonctionnalite`)
5. Ouvrez une Pull Request

---

**Projet √©ducatif** - Ce scraper est destin√© √† l'apprentissage des techniques de web scraping  
‚ö†Ô∏è Respectez toujours les conditions d'utilisation des sites scrap√©s


## üåê Donn√©es Compl√®tes
[https://books.toscrape.com/]

![License MIT](https://img.shields.io/badge/License-MIT-green)
```